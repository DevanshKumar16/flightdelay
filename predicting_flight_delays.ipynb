{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2748e977",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-25T10:50:49.601071Z",
     "iopub.status.busy": "2021-12-25T10:50:49.599757Z",
     "iopub.status.idle": "2021-12-25T10:51:40.044239Z",
     "shell.execute_reply": "2021-12-25T10:51:40.043361Z",
     "shell.execute_reply.started": "2021-12-25T08:50:52.089284Z"
    },
    "papermill": {
     "duration": 50.472762,
     "end_time": "2021-12-25T10:51:40.044448",
     "exception": false,
     "start_time": "2021-12-25T10:50:49.571686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.2.0.tar.gz (281.3 MB)\r\n",
      "     |████████████████████████████████| 281.3 MB 32 kB/s              \r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hCollecting py4j==0.10.9.2\r\n",
      "  Downloading py4j-0.10.9.2-py2.py3-none-any.whl (198 kB)\r\n",
      "     |████████████████████████████████| 198 kB 41.2 MB/s            \r\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.0-py2.py3-none-any.whl size=281805912 sha256=29c3190b8ba5bba69def63afacc724a83374753847bce001e2e6ff78471b918b\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/de/d2/9be5d59d7331c6c2a7c1b6d1a4f463ce107332b1ecd4e80718\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: py4j, pyspark\r\n",
      "  Attempting uninstall: py4j\r\n",
      "    Found existing installation: py4j 0.10.9.3\r\n",
      "    Uninstalling py4j-0.10.9.3:\r\n",
      "      Successfully uninstalled py4j-0.10.9.3\r\n",
      "Successfully installed py4j-0.10.9.2 pyspark-3.2.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759dba24",
   "metadata": {
    "papermill": {
     "duration": 0.155335,
     "end_time": "2021-12-25T10:51:40.361133",
     "exception": false,
     "start_time": "2021-12-25T10:51:40.205798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Predicting flight delays using PySpark**\n",
    "\n",
    "In this Notebook we will predict flight delays using PySpark. We will use to basic machine learning models namely **Descision Tree** and **Logistic Regression** to achieve this task. \n",
    "\n",
    "Spark is currently the most popular technology to  process and work with big(large quantities) data. Also, in camparision to other distributed computing technologies, working with Spark is easier even for begginers. We will interact with spark using python PySpark library.\n",
    "\n",
    "# Input Data\n",
    "We are going to use some airline flight data as a CSV file as input data. Short description of data fields is following:\n",
    "\n",
    "**Data columns:**\n",
    "\n",
    "mon — month (int between 1 and 12)\n",
    "\n",
    "dom — day of month (int between 1 and 31)\n",
    "\n",
    "dow — day of week (int; 1 = Monday and 7 = Sunday)\n",
    "\n",
    "org — origin airport (str; IATA code)\n",
    "\n",
    "mile — distance (int; miles)\n",
    "\n",
    "carrier — carrier (str; IATA code)\n",
    "\n",
    "depart — departure time (int; decimal hour)\n",
    "\n",
    "duration — expected duration (int; minutes)\n",
    "\n",
    "delay — delay (int; minutes)\n",
    "\n",
    "(IATA -> International Air Transport Association)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d17cd",
   "metadata": {
    "papermill": {
     "duration": 0.154351,
     "end_time": "2021-12-25T10:51:40.666702",
     "exception": false,
     "start_time": "2021-12-25T10:51:40.512351",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7511d07",
   "metadata": {
    "papermill": {
     "duration": 0.155475,
     "end_time": "2021-12-25T10:51:40.978263",
     "exception": false,
     "start_time": "2021-12-25T10:51:40.822788",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Importing neccessary packages and libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d14a49bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:41.297865Z",
     "iopub.status.busy": "2021-12-25T10:51:41.297076Z",
     "iopub.status.idle": "2021-12-25T10:51:41.635123Z",
     "shell.execute_reply": "2021-12-25T10:51:41.634474Z",
     "shell.execute_reply.started": "2021-12-25T10:47:47.708480Z"
    },
    "papermill": {
     "duration": 0.498697,
     "end_time": "2021-12-25T10:51:41.635279",
     "exception": false,
     "start_time": "2021-12-25T10:51:41.136582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "\n",
    "from pyspark.sql.functions import round\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator, BinaryClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153fb7cc",
   "metadata": {
    "papermill": {
     "duration": 0.149869,
     "end_time": "2021-12-25T10:51:41.936201",
     "exception": false,
     "start_time": "2021-12-25T10:51:41.786332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We will use a local Spark cluster using all available cores, which will be accessible via a SparkSession object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f7ccf4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:42.259686Z",
     "iopub.status.busy": "2021-12-25T10:51:42.258859Z",
     "iopub.status.idle": "2021-12-25T10:51:48.630256Z",
     "shell.execute_reply": "2021-12-25T10:51:48.629531Z",
     "shell.execute_reply.started": "2021-12-25T10:48:08.368259Z"
    },
    "papermill": {
     "duration": 6.533526,
     "end_time": "2021-12-25T10:51:48.630405",
     "exception": false,
     "start_time": "2021-12-25T10:51:42.096879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/conda/lib/python3.7/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/12/25 10:51:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "                    .master('local[*]') \\\n",
    "                    .appName('ML with PySpark') \\\n",
    "                    .getOrCreate()\n",
    "# What version of Spark?\n",
    "print(spark.version)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fb7b59",
   "metadata": {
    "papermill": {
     "duration": 0.159708,
     "end_time": "2021-12-25T10:51:48.958455",
     "exception": false,
     "start_time": "2021-12-25T10:51:48.798747",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Basic data exploration\n",
    "\n",
    "\n",
    "Exploring basic info like:\n",
    "\n",
    "- How many records?\n",
    "- Which datatypes?\n",
    "- missing values etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05a49771",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:49.278701Z",
     "iopub.status.busy": "2021-12-25T10:51:49.277922Z",
     "iopub.status.idle": "2021-12-25T10:51:56.022789Z",
     "shell.execute_reply": "2021-12-25T10:51:56.022081Z",
     "shell.execute_reply.started": "2021-12-25T10:48:13.911344Z"
    },
    "papermill": {
     "duration": 6.90769,
     "end_time": "2021-12-25T10:51:56.022946",
     "exception": false,
     "start_time": "2021-12-25T10:51:49.115256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flights_df = spark.read.csv('../input/pyspark-datasets/flights-larger.csv',\n",
    "                         sep=',',\n",
    "                         header=True,\n",
    "                         inferSchema=True,\n",
    "                         nullValue='NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a91755a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:56.347869Z",
     "iopub.status.busy": "2021-12-25T10:51:56.345494Z",
     "iopub.status.idle": "2021-12-25T10:51:57.621231Z",
     "shell.execute_reply": "2021-12-25T10:51:57.620411Z",
     "shell.execute_reply.started": "2021-12-25T10:48:20.460728Z"
    },
    "papermill": {
     "duration": 1.43292,
     "end_time": "2021-12-25T10:51:57.621447",
     "exception": false,
     "start_time": "2021-12-25T10:51:56.188527",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data contain 275000 records.\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "|mon|dom|dow|carrier|flight|org|mile|depart|duration|delay|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "| 10| 10|  1|     OO|  5836|ORD| 157|  8.18|      51|   27|\n",
      "|  1|  4|  1|     OO|  5866|ORD| 466|  15.5|     102| null|\n",
      "| 11| 22|  1|     OO|  6016|ORD| 738|  7.17|     127|  -19|\n",
      "|  2| 14|  5|     B6|   199|JFK|2248| 21.17|     365|   60|\n",
      "|  5| 25|  3|     WN|  1675|SJC| 386| 12.92|      85|   22|\n",
      "+---+---+---+-------+------+---+----+------+--------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get number of records\n",
    "print(\"The data contain %d records.\" % flights_df.count())\n",
    "# View the first five records\n",
    "flights_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3edb6212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:58.022243Z",
     "iopub.status.busy": "2021-12-25T10:51:58.021535Z",
     "iopub.status.idle": "2021-12-25T10:51:58.057624Z",
     "shell.execute_reply": "2021-12-25T10:51:58.056941Z",
     "shell.execute_reply.started": "2021-12-25T10:48:23.443626Z"
    },
    "papermill": {
     "duration": 0.278973,
     "end_time": "2021-12-25T10:51:58.057787",
     "exception": false,
     "start_time": "2021-12-25T10:51:57.778814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('mon', 'int'), ('dom', 'int'), ('dow', 'int'), ('carrier', 'string'), ('flight', 'int'), ('org', 'string'), ('mile', 'int'), ('depart', 'double'), ('duration', 'int'), ('delay', 'int')]\n"
     ]
    }
   ],
   "source": [
    "# Check column data types\n",
    "print(flights_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1bd912",
   "metadata": {
    "papermill": {
     "duration": 0.150646,
     "end_time": "2021-12-25T10:51:58.362080",
     "exception": false,
     "start_time": "2021-12-25T10:51:58.211434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Data preparation for training our ML model**\n",
    "\n",
    "# Data Prepartion includes:\n",
    "\n",
    "**Data Cleaning**\n",
    "- removing an uninformative column and\n",
    "- removing rows having missing vlaues\n",
    "\n",
    "**Column/Data manipulation**\n",
    "- We will consider a flight to be \"delayed\" when it arrives 15 minutes or more after its scheduled time (this complies with FAA's defintion of delayed flight\n",
    "- Based on this definition, we will create new boolean column 'label' stating if a flight was delayed or not\n",
    "- Convert columns that hold categorical data(carrier & org) into indexed numerical values\n",
    "\n",
    "**Assembling columns**\n",
    "- The final stage consists of  consolidating all predictor columns into a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "223dfcd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:51:58.679198Z",
     "iopub.status.busy": "2021-12-25T10:51:58.678087Z",
     "iopub.status.idle": "2021-12-25T10:51:59.892314Z",
     "shell.execute_reply": "2021-12-25T10:51:59.891206Z",
     "shell.execute_reply.started": "2021-12-25T10:48:27.139110Z"
    },
    "papermill": {
     "duration": 1.37693,
     "end_time": "2021-12-25T10:51:59.892535",
     "exception": false,
     "start_time": "2021-12-25T10:51:58.515605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===================>                                       (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "258289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Remove the 'flight' column\n",
    "flights_df =  flights_df.drop('flight')\n",
    "\n",
    "# Remove records with missing 'delay' values\n",
    "#flights_valid_delay = flights_drop_column.filter('delay IS NOT NULL')\n",
    "\n",
    "# Remove records with missing values \n",
    "flights_df = flights_df.dropna()\n",
    "print(flights_df.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b1667d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:00.363936Z",
     "iopub.status.busy": "2021-12-25T10:52:00.362922Z",
     "iopub.status.idle": "2021-12-25T10:52:00.747892Z",
     "shell.execute_reply": "2021-12-25T10:52:00.749487Z",
     "shell.execute_reply.started": "2021-12-25T10:48:34.054818Z"
    },
    "papermill": {
     "duration": 0.586285,
     "end_time": "2021-12-25T10:52:00.749892",
     "exception": false,
     "start_time": "2021-12-25T10:52:00.163607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert columns 'mile' to 'km' and then drop it\n",
    "flights_km = flights_df.withColumn('km', round(flights_df.mile * 1.60934, 0)) \\\n",
    "                    .drop('mile')\n",
    "\n",
    "# Create 'label' column indicating whether a flight is delayed or not\n",
    "flights_km = flights_km.withColumn('label', (flights_km.delay >= 15).cast('integer'))\n",
    "\n",
    "# Check first five records\n",
    "flights_km.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411f61dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:01.081287Z",
     "iopub.status.busy": "2021-12-25T10:52:01.080295Z",
     "iopub.status.idle": "2021-12-25T10:52:04.809268Z",
     "shell.execute_reply": "2021-12-25T10:52:04.810366Z",
     "shell.execute_reply.started": "2021-12-25T10:48:37.647846Z"
    },
    "papermill": {
     "duration": 3.889842,
     "end_time": "2021-12-25T10:52:04.810636",
     "exception": false,
     "start_time": "2021-12-25T10:52:00.920794",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "|mon|dom|dow|carrier|org|depart|duration|delay|    km|label|carrier_idx|org_idx|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "| 10| 10|  1|     OO|ORD|  8.18|      51|   27| 253.0|    1|        2.0|    0.0|\n",
      "| 11| 22|  1|     OO|ORD|  7.17|     127|  -19|1188.0|    0|        2.0|    0.0|\n",
      "|  2| 14|  5|     B6|JFK| 21.17|     365|   60|3618.0|    1|        4.0|    2.0|\n",
      "|  5| 25|  3|     WN|SJC| 12.92|      85|   22| 621.0|    1|        3.0|    5.0|\n",
      "|  3| 28|  1|     B6|LGA| 13.33|     182|   70|1732.0|    1|        4.0|    3.0|\n",
      "+---+---+---+-------+---+------+--------+-----+------+-----+-----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an indexer, which identifies categories and then creates a new column with numeric index values\n",
    "flights_indexed = StringIndexer(inputCol='carrier', outputCol='carrier_idx').fit(flights_km).transform(flights_km)\n",
    "\n",
    "# Repeat the process for org column\n",
    "flights_indexed = StringIndexer(inputCol='org', outputCol='org_idx').fit(flights_indexed).transform(flights_indexed)\n",
    "flights_indexed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb6fa6a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:05.263492Z",
     "iopub.status.busy": "2021-12-25T10:52:05.262459Z",
     "iopub.status.idle": "2021-12-25T10:52:05.877480Z",
     "shell.execute_reply": "2021-12-25T10:52:05.876390Z",
     "shell.execute_reply.started": "2021-12-25T10:48:42.159810Z"
    },
    "papermill": {
     "duration": 0.802338,
     "end_time": "2021-12-25T10:52:05.877720",
     "exception": false,
     "start_time": "2021-12-25T10:52:05.075382",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------------+-----+\n",
      "|features                                 |delay|\n",
      "+-----------------------------------------+-----+\n",
      "|[10.0,10.0,1.0,2.0,0.0,253.0,8.18,51.0]  |27   |\n",
      "|[11.0,22.0,1.0,2.0,0.0,1188.0,7.17,127.0]|-19  |\n",
      "|[2.0,14.0,5.0,4.0,2.0,3618.0,21.17,365.0]|60   |\n",
      "|[5.0,25.0,3.0,3.0,5.0,621.0,12.92,85.0]  |22   |\n",
      "|[3.0,28.0,1.0,4.0,3.0,1732.0,13.33,182.0]|70   |\n",
      "+-----------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create an assembler object\n",
    "assembler = VectorAssembler(inputCols=['mon', 'dom', 'dow',\n",
    "'carrier_idx', 'org_idx', 'km', 'depart', 'duration'], outputCol='features')\n",
    "# Consolidate predictor columns\n",
    "flights_assembled = assembler.transform(flights_indexed)\n",
    "# Check the resulting column\n",
    "flights_assembled.select('features', 'delay').show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd252fcb",
   "metadata": {
    "papermill": {
     "duration": 0.156295,
     "end_time": "2021-12-25T10:52:06.290530",
     "exception": false,
     "start_time": "2021-12-25T10:52:06.134235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# **Machine Learning Models**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2626a7",
   "metadata": {
    "papermill": {
     "duration": 0.155221,
     "end_time": "2021-12-25T10:52:06.608827",
     "exception": false,
     "start_time": "2021-12-25T10:52:06.453606",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# First classification model:\n",
    "\n",
    "**Decision Trees: offers inherit simplicity and explanablility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a8fd84c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:06.924643Z",
     "iopub.status.busy": "2021-12-25T10:52:06.923966Z",
     "iopub.status.idle": "2021-12-25T10:52:11.461809Z",
     "shell.execute_reply": "2021-12-25T10:52:11.460986Z",
     "shell.execute_reply.started": "2021-12-25T10:49:03.040007Z"
    },
    "papermill": {
     "duration": 4.698709,
     "end_time": "2021-12-25T10:52:11.462000",
     "exception": false,
     "start_time": "2021-12-25T10:52:06.763291",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7998753334443202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Split into training and testing sets in a 80:20 ratio\n",
    "flights_train, flights_test = flights_assembled.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Check that training set has around 80% of records\n",
    "training_ratio = flights_train.count() / flights_assembled.count()\n",
    "print(training_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfaafd52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:11.818828Z",
     "iopub.status.busy": "2021-12-25T10:52:11.817767Z",
     "iopub.status.idle": "2021-12-25T10:52:26.737256Z",
     "shell.execute_reply": "2021-12-25T10:52:26.736696Z",
     "shell.execute_reply.started": "2021-12-25T10:49:09.060781Z"
    },
    "papermill": {
     "duration": 15.082875,
     "end_time": "2021-12-25T10:52:26.737410",
     "exception": false,
     "start_time": "2021-12-25T10:52:11.654535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 41:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+----------------------------------------+\n",
      "|label|prediction|probability                             |\n",
      "+-----+----------+----------------------------------------+\n",
      "|0    |1.0       |[0.31856586262750075,0.6814341373724992]|\n",
      "|1    |0.0       |[0.6183646554566435,0.3816353445433564] |\n",
      "|1    |0.0       |[0.6183646554566435,0.3816353445433564] |\n",
      "|1    |1.0       |[0.31856586262750075,0.6814341373724992]|\n",
      "|1    |1.0       |[0.31856586262750075,0.6814341373724992]|\n",
      "+-----+----------+----------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a DT classifier object and fit to the training data\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_model = tree.fit(flights_train)\n",
    "# Create predictions on test data\n",
    "prediction = tree_model.transform(flights_test)\n",
    "prediction.select('label', 'prediction', 'probability').show(5, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd513a",
   "metadata": {
    "papermill": {
     "duration": 0.168247,
     "end_time": "2021-12-25T10:52:27.081299",
     "exception": false,
     "start_time": "2021-12-25T10:52:26.913052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Evaluate the model**\n",
    "A confusion matrix gives a useful breakdown of predictions versus known values. It has four cells which represent the counts of:\n",
    "True Negatives (TN) — prediction is negative & label is negative\n",
    "\n",
    "True Positives (TP) — prediction is positive & label is positive\n",
    "\n",
    "False Negatives (FN) — prediction is negative & label is positive\n",
    "\n",
    "False Positives (FP) — prediction is positive & label is negative\n",
    "\n",
    "Using these four measure, we can then calculate the accuravy of the model as follows:\n",
    "\n",
    "**Accuracy=(TN+TP)/(TN+TP+FN+FP)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e3b422c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:27.435375Z",
     "iopub.status.busy": "2021-12-25T10:52:27.434253Z",
     "iopub.status.idle": "2021-12-25T10:52:38.485661Z",
     "shell.execute_reply": "2021-12-25T10:52:38.486743Z",
     "shell.execute_reply.started": "2021-12-25T10:49:24.367857Z"
    },
    "papermill": {
     "duration": 11.242168,
     "end_time": "2021-12-25T10:52:38.487082",
     "exception": false,
     "start_time": "2021-12-25T10:52:27.244914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9666|\n",
      "|    0|       0.0|16350|\n",
      "|    1|       1.0|16349|\n",
      "|    0|       1.0| 9325|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 54:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6325981814664345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a confusion matrix\n",
    "prediction.groupBy('label', 'prediction').count().show()\n",
    "\n",
    "# Calculate the elements of the confusion matrix\n",
    "TN = prediction.filter('prediction = 0 AND label = prediction').count()\n",
    "TP = prediction.filter('prediction = 1 AND label = prediction').count()\n",
    "FN = prediction.filter('prediction = 0 AND label != prediction').count()\n",
    "FP = prediction.filter('prediction = 1 AND label != prediction').count()\n",
    "\n",
    "# Accuracy measures the proportion of correct predictions\n",
    "accuracy = (TN + TP) / (TN + TP + FN + FP)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ef8468",
   "metadata": {
    "papermill": {
     "duration": 0.166829,
     "end_time": "2021-12-25T10:52:38.853763",
     "exception": false,
     "start_time": "2021-12-25T10:52:38.686934",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The accuracy is decent but not a good one. We have a lot of false predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333461c4",
   "metadata": {
    "papermill": {
     "duration": 0.169048,
     "end_time": "2021-12-25T10:52:39.191622",
     "exception": false,
     "start_time": "2021-12-25T10:52:39.022574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Seocond classification model:\n",
    "\n",
    "**Logistic Regression: simple and easy to train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02c7cf3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:39.538772Z",
     "iopub.status.busy": "2021-12-25T10:52:39.538075Z",
     "iopub.status.idle": "2021-12-25T10:52:49.549661Z",
     "shell.execute_reply": "2021-12-25T10:52:49.548710Z",
     "shell.execute_reply.started": "2021-12-25T10:49:42.041216Z"
    },
    "papermill": {
     "duration": 10.1885,
     "end_time": "2021-12-25T10:52:49.549875",
     "exception": false,
     "start_time": "2021-12-25T10:52:39.361375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 76:===================>                                      (1 + 2) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+-----+\n",
      "|label|prediction|count|\n",
      "+-----+----------+-----+\n",
      "|    1|       0.0| 9471|\n",
      "|    0|       0.0|14934|\n",
      "|    1|       1.0|16544|\n",
      "|    0|       1.0|10741|\n",
      "+-----+----------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create a classifier object and train on training data\n",
    "logistic = LogisticRegression().fit(flights_train)\n",
    "# Create predictions for the testing data and show confusion matrix\n",
    "prediction = logistic.transform(flights_test)\n",
    "prediction.groupBy('label', 'prediction').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70933b1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:49.992334Z",
     "iopub.status.busy": "2021-12-25T10:52:49.991283Z",
     "iopub.status.idle": "2021-12-25T10:52:56.755961Z",
     "shell.execute_reply": "2021-12-25T10:52:56.754891Z",
     "shell.execute_reply.started": "2021-12-25T10:49:55.449495Z"
    },
    "papermill": {
     "duration": 6.949753,
     "end_time": "2021-12-25T10:52:56.756174",
     "exception": false,
     "start_time": "2021-12-25T10:52:49.806421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.64\n",
      "recall    = 0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Calculate precision and recall\n",
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print('precision = {:.2f}\\nrecall    = {:.2f}'.format(precision, recall))\n",
    "\n",
    "# Find weighted precision\n",
    "multi_evaluator = MulticlassClassificationEvaluator()\n",
    "weighted_precision = multi_evaluator.evaluate(prediction, {multi_evaluator.metricName: \"weightedPrecision\"})\n",
    "\n",
    "# Find AUC\n",
    "binary_evaluator = BinaryClassificationEvaluator()\n",
    "auc = binary_evaluator.evaluate(prediction, {binary_evaluator.metricName: \"areaUnderROC\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbee3d4",
   "metadata": {
    "papermill": {
     "duration": 0.173125,
     "end_time": "2021-12-25T10:52:57.104146",
     "exception": false,
     "start_time": "2021-12-25T10:52:56.931021",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Again the matrices are reflecting decent values but not good ones. Which means, improving in models' efficiency can be considered as potential future work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073d3a6b",
   "metadata": {
    "papermill": {
     "duration": 0.17092,
     "end_time": "2021-12-25T10:52:57.447397",
     "exception": false,
     "start_time": "2021-12-25T10:52:57.276477",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please provide your valuable feedback and tips to improve efficiency or better models. If you found the notebook interesting or learn anything new, then please don't forget to upvote :-)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd22da4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-25T10:52:57.795657Z",
     "iopub.status.busy": "2021-12-25T10:52:57.794965Z",
     "iopub.status.idle": "2021-12-25T10:52:58.034878Z",
     "shell.execute_reply": "2021-12-25T10:52:58.034177Z",
     "shell.execute_reply.started": "2021-12-25T10:50:24.620823Z"
    },
    "papermill": {
     "duration": 0.416213,
     "end_time": "2021-12-25T10:52:58.035042",
     "exception": false,
     "start_time": "2021-12-25T10:52:57.618829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Close spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86834c1",
   "metadata": {
    "papermill": {
     "duration": 0.175879,
     "end_time": "2021-12-25T10:52:58.386324",
     "exception": false,
     "start_time": "2021-12-25T10:52:58.210445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 140.014715,
   "end_time": "2021-12-25T10:52:59.371542",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-25T10:50:39.356827",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
